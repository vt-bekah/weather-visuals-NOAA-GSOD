{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe167c7b-e140-4674-bda4-b1205ab8c5d6",
   "metadata": {},
   "source": [
    "**Prerequisites to running this notebook:**\n",
    "1. Install the following in your dev environment:<br>\n",
    "    a. google-cloud-bigquery: pip.exe install google-cloud-bigquery<br>\n",
    "    b. db-types: pip install db-dtypes<br>\n",
    "2. Install gcloud CLI <br>\n",
    "    a. Install directions (with download link): https://cloud.google.com/sdk/docs/install<br>\n",
    "    > i. pay attention to where it installs to add this to your PATH environmental variables<br>\n",
    "    > ii. It says to leave all the shortcut, open terminal options checked. I received errors when it ran \"gcloud info --run-diagnostics\" and I ignored them until I updated the PATH envrionmental variables<br>\n",
    "    \n",
    "    b. Add this to your PATH environmental variables (for me this was C:\\Users\\vt_be\\AppData\\Local\\Google\\Cloud SDK\\google-cloud-sdk)<br>\n",
    "    c. reboot!<br>\n",
    "    d. open git bash, switch to dev environment<br>\n",
    "    > i. \"gcloud info --run-diagnostics\" now ran without issue<br>\n",
    "    ii. add authentication (this opens browser to connect your google account):  gcloud auth application-default login<br>\n",
    "    \n",
    "    e. I also needed to set up a Big Query Project: mostly followed https://cloud.google.com/bigquery/docs/sandbox<br>\n",
    "    > i. I didn't see the stuff mentioned in #3 but it otherwise worked as written<br>\n",
    "    > ii. Note that when you create the project, an id is generated that is project name - #### (for me BootCamp-Weather:  bootcamp-weather-400118<br>\n",
    "    \n",
    "    f. Add the project to default - back to gitbash: gcloud auth application-default set-quota-project <project-id><br>\n",
    "3. Create a config.py file in the folder that contains this notebook. \n",
    "4. Add the following variable to config.py: google_project = \"your-project-id\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6afa289-a8e3-41ff-8560-a264165f8592",
   "metadata": {},
   "source": [
    "**Credit:**\n",
    "* Big Query calls adapted from https://www.kaggle.com/code/crained/noaa-dataset-with-google-bigquery\n",
    "* SQL calls adapted from GitHub BigQuery documentation: https://github.com/googleapis/python-bigquery\n",
    "\n",
    "**Data Info:**\n",
    "https://data.noaa.gov/dataset/dataset/global-surface-summary-of-the-day-gsod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07b37292-6d41-4493-9c3f-9d36d533c7f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since this is unique to user, I added config.py to the gitignore. \n",
    "# You must create your own config.py file with project name as stated in the Prerequisites\n",
    "from config import google_project\n",
    "# bigquery and pandas work well together for dataframes!\n",
    "import pandas as pd\n",
    "import os\n",
    "# Follow the prerequisite instructions to get bigquery going\n",
    "from google.cloud import bigquery\n",
    "# Create a \"Client\" object reference a google project for which your system has been authenticated\n",
    "client = bigquery.Client(google_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca642256-4cd1-47f9-a42a-7e9c6148b272",
   "metadata": {},
   "source": [
    "**Optional print the table schemas to better understand the data** <br>\n",
    "Commented out here due to length of output for complete notebook execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2d09b0-4804-4251-8d51-d86be6787a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Stations table\n",
    "# # Construct a reference to the \"full\" table\n",
    "# table_ref2 = dataset_ref.table(\"stations\")\n",
    "# # API request - fetch the table\n",
    "# table2 = client.get_table(table_ref2)\n",
    "# # Print information on all the columns\n",
    "# table2.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbf31bd-0a94-47c1-87de-e5e5429784f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Measurements table for 2022\n",
    "# # Construct a reference to the \"full\" table\n",
    "# table_ref = dataset_ref.table(\"gsod2022\")\n",
    "# # API request - fetch the table\n",
    "# table = client.get_table(table_ref)\n",
    "# # Print information on all the columns\n",
    "# table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ff556-c2aa-4828-8b34-c49def3145e3",
   "metadata": {},
   "source": [
    "## Query for the Stations static info ##\n",
    "usaf for connecting tables, <br>\n",
    "spatial data required for heatmap, <br>\n",
    "name and state for usability <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aef2c4cc-5c08-4a9c-b4e5-f612f09cd8e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 3790 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>720511</td>\n",
       "      <td>BRITTON MUNI</td>\n",
       "      <td>SD</td>\n",
       "      <td>45.815</td>\n",
       "      <td>-97.743</td>\n",
       "      <td>+0401.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>723062</td>\n",
       "      <td>PINEY ISLAND</td>\n",
       "      <td>NC</td>\n",
       "      <td>35.020</td>\n",
       "      <td>-76.460</td>\n",
       "      <td>+0005.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00030</td>\n",
       "      <td>CONNELLSVILLE AIRPORT</td>\n",
       "      <td>PA</td>\n",
       "      <td>39.959</td>\n",
       "      <td>-79.657</td>\n",
       "      <td>+0386.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720844</td>\n",
       "      <td>SPANISH PEAKS</td>\n",
       "      <td>CO</td>\n",
       "      <td>37.697</td>\n",
       "      <td>-104.785</td>\n",
       "      <td>+1844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>724916</td>\n",
       "      <td>MARINA MUNI</td>\n",
       "      <td>CA</td>\n",
       "      <td>36.682</td>\n",
       "      <td>-121.762</td>\n",
       "      <td>+0040.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaf                   name state     lat      lon     elev\n",
       "0  720511           BRITTON MUNI    SD  45.815  -97.743  +0401.7\n",
       "1  723062           PINEY ISLAND    NC  35.020  -76.460  +0005.2\n",
       "2  A00030  CONNELLSVILLE AIRPORT    PA  39.959  -79.657  +0386.2\n",
       "3  720844          SPANISH PEAKS    CO  37.697 -104.785  +1844.0\n",
       "4  724916            MARINA MUNI    CA  36.682 -121.762  +0040.8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Station IDs (usaf) remained consistent to the physical station over time, but names changed resulting in multiple entries with same usaf. \n",
    "# This query will sort by begin date descending so we can use the pandas remove duplicates function to keep the latest name only.\n",
    "\n",
    "# Define the SQl suery\n",
    "QUERY = (\n",
    "    'SELECT usaf, name, state, lat, lon, elev '\n",
    "    'FROM `bigquery-public-data.noaa_gsod.stations` '\n",
    "    'WHERE country = \"US\" AND state <> \"None\" '\n",
    "    'ORDER BY begin DESC'\n",
    "    )\n",
    "# API request\n",
    "stations_result = client.query(QUERY)  \n",
    "# Waits for query to finish\n",
    "stations_data = stations_result.result()  \n",
    "\n",
    "# Put the query into a dataframe\n",
    "stations_data_df = stations_data.to_dataframe()\n",
    "\n",
    "# Remove duplicate stations by usaf\n",
    "stations_data_df = stations_data_df.drop_duplicates(\"usaf\")\n",
    "\n",
    "# # and export if desired (not required for final implementation)\n",
    "# stations_data_df.to_json(\"./data/Stations.json\", orient=\"records\")\n",
    "# stations_data_df.to_csv(\"./data/Stations.csv\")\n",
    "\n",
    "print(f' There are {len(stations_data_df)} rows')\n",
    "stations_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8e4f83-04de-4ee7-9132-bc0396bfdd2d",
   "metadata": {},
   "source": [
    "## Query for the temperature data ##\n",
    "### Query for temperature stats (similar filtering) by station ###\n",
    "SchemaField('min', 'FLOAT', 'NULLABLE', None, 'Minimum temperature reported during the day in Fahrenheit to tenths--time of min temp report varies by country and region, so this will sometimes not be the min for the calendar day. Missing = 9999.9', (), None),<br>\n",
    "SchemaField('temp', 'FLOAT', 'NULLABLE', None, 'Mean temperature for the day in degrees Fahrenheit to tenths. Missing = 9999.9', (), None),<br>\n",
    "SchemaField('max', 'FLOAT', 'NULLABLE', None, 'Maximum temperature reported during the day in Fahrenheit to tenths--time of max temp report varies by country and region, so this will sometimes not be the max for the calendar day. Missing = 9999.9', (), None),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "211c0861-b668-4304-969a-99a0f068ab13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 2522 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>max_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702490</td>\n",
       "      <td>-27.4</td>\n",
       "      <td>32.636119</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702606</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>24.352830</td>\n",
       "      <td>55.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703333</td>\n",
       "      <td>21.9</td>\n",
       "      <td>45.812844</td>\n",
       "      <td>69.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703406</td>\n",
       "      <td>-22.0</td>\n",
       "      <td>42.212132</td>\n",
       "      <td>82.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>703656</td>\n",
       "      <td>-32.8</td>\n",
       "      <td>35.676400</td>\n",
       "      <td>80.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaf  min_temp  mean_temp  max_temp\n",
       "0  702490     -27.4  32.636119      77.0\n",
       "1  702606      -7.6  24.352830      55.4\n",
       "2  703333      21.9  45.812844      69.1\n",
       "3  703406     -22.0  42.212132      82.4\n",
       "4  703656     -32.8  35.676400      80.1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query to get absoulte minimum temperature, average mean temperature, absolute maximum temperature \n",
    "# for the year by station (usaf)\n",
    "aggregate_query = (\n",
    "    'SELECT s.usaf, '\n",
    "    'MIN(g.min) AS min_temp, '\n",
    "    'AVG(g.temp) AS mean_temp, '\n",
    "    'MAX(g.max) AS max_temp, '\n",
    "    'FROM `bigquery-public-data.noaa_gsod.gsod2022` AS g '\n",
    "    'INNER JOIN `bigquery-public-data.noaa_gsod.stations` AS s ON g.stn = s.usaf '\n",
    "    'WHERE s.country = \"US\" AND s.state <> \"None\" '\n",
    "    # The line below removes the 'not a reading' so we can run stats on those columns\n",
    "    'AND g.min <> 9999.9 AND g.max <> 9999.9 '\n",
    "    'GROUP BY s.usaf '\n",
    "    )\n",
    "\n",
    "# API request\n",
    "station_temp_result = client.query(aggregate_query)  \n",
    "# Waits for query to finish\n",
    "station_temp_data = station_temp_result.result()  \n",
    "\n",
    "# Put the query into a dataframe\n",
    "station_temp_df = station_temp_result.to_dataframe()\n",
    "\n",
    "# # and export if desired (not required for final implementation)\n",
    "# state_temp_station.to_json(\"./data/Station_temp_sample.json\", orient=\"records\")\n",
    "# state_temp_station.to_csv(\"./data/Station_temp_sample.csv\")\n",
    "\n",
    "print(f' There are {len(station_temp_df)} rows')\n",
    "station_temp_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd9c67-354b-461f-9392-e21d99dcf8e0",
   "metadata": {},
   "source": [
    "### Query for total precipitation in a year ###\n",
    "SchemaField('prcp', 'FLOAT', 'NULLABLE', None, \"Total precipitation (rain and/or melted snow) reported during the day in inches and hundredths; will usually not end with the midnight observation--i.e., may include latter part of previous day.  .00 indicates no measurable precipitation (includes a trace). Missing = 99.99 Note: Many stations do not report '0' on days with no precipitation--therefore, '99.99' will often appear on these days. Understand this to see if need to include a filter around teh flag\n",
    "Also, for example, a station may only report a 6-hour amount for the period during which rain fell. See Flag field for source of data\", (), None),\n",
    "\n",
    "\n",
    " SchemaField('flag_prcp', 'STRING', 'NULLABLE', None, \"A = 1 report of 6-hour precipitation amount B = Summation of 2 reports of 6-hour precipitation amount C = Summation of 3 reports of 6-hour precipitation amount D = Summation of 4 reports of 6-hour precipitation amount E = 1 report of 12-hour precipitation amount F = Summation of 2 reports of 12-hour precipitation amount G = 1 report of 24-hour precipitation amount H = Station reported '0' as the amount for the day (eg, from 6-hour reports), but also reported at least one occurrence of precipitation in hourly observations--this could indicate a trace occurred, but should be considered as incomplete data for the day. I = Station did not report any precip data for the day and did not report any occurrences of precipitation in its hourly observations--it's still possible that precip occurred but was not reported\", (), None),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb69e22-44fa-46b4-b801-bf6b670a72ad",
   "metadata": {},
   "source": [
    "**Due to the different ways stations are allowed to take measurements, there are duplicate readings in a single day for some stations** <br>\n",
    "In particular, there is one station (999999) that behaves differently than the rest but within the schema that requires further clean-up.<br>\n",
    "To work through this, a more detailed query is need that returns millions of rows taking quite a bit of time. This query was executed and then duplicates removed and stored in a csv and json files so the query would not have to be run again. The query is commented out and the re-load of the csv file is kept for default running of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73723024-a1fc-49c6-b9b9-ee92a59465da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Perform a query for the sum of precipitation for each station over the year\n",
    "# aggregate_query = (\n",
    "#     'SELECT s.usaf, g.mo, g.da, g.prcp, g.flag_prcp '\n",
    "#     # 'SUM(g.prcp) AS total_precipitation '\n",
    "#     'FROM `bigquery-public-data.noaa_gsod.gsod2022` AS g '\n",
    "#     'INNER JOIN `bigquery-public-data.noaa_gsod.stations` AS s ON g.stn = s.usaf '\n",
    "#     'WHERE s.country = \"US\" AND s.state <> \"None\" '\n",
    "#     # The line below removes the 'not a reading' so we can run stats on those columns\n",
    "#     'AND g.prcp <> 99.99 '\n",
    "#     # 'GROUP BY s.usaf'\n",
    "# )\n",
    "# station_prcp_result = client.query(aggregate_query)  # API request\n",
    "# station_prcp_data = station_prcp_result.result()  # Waits for query to finish\n",
    "\n",
    "# # Put the query into a dataframe\n",
    "# station_prcp_long_df = station_prcp_result.to_dataframe()\n",
    "\n",
    "# # An export at this level produces files at the gigabyte level so it is not recommended\n",
    "# # station_prcp_long_df.to_csv(\"stations_rain_with_dup.csv\")\n",
    "# # station_prcp_long_df.to_json(\"stations_rain_with_dup.json\", orient=\"records\")\n",
    "\n",
    "# # Drop duplicates across usaf\tmo\tda\tprcp (duplicates are allowed by multiple flags)\n",
    "# # Remove duplicate station day reports\n",
    "# station_prcp_long_nodup = station_prcp_long_df.drop_duplicates([\"usaf\", \"mo\", \"da\", \"prcp\"])\n",
    "\n",
    "# station_prcp_long_nodup.to_csv(\"../data/stations_prcp_detail.csv\")\n",
    "# station_prcp_long_nodup.to_json(\"../data/stations_prcp_detail.json\", orient=\"records\")\n",
    "\n",
    "# print(f' There are {len(station_prcp_long_nodup)} rows')\n",
    "# station_prcp_long_nodup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34946ac6-995b-4302-ac1e-ad60da719511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read in the file exported in the commented code to the same dataframe.\n",
    "# If you chose to run the above cell, this cell may be commented out.\n",
    "station_prcp_long_nodup = pd.read_csv('../data/stations_prcp_detail.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b6be559-da05-4653-a6fa-90ffa492fb65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removing overlapping readings (station 99999 for the 2022 pull but could be more stations in other years)\n",
    "\n",
    "# Sort the stations by station -> month -> day -> prcp in descending order. \n",
    "# This puts the highest measurement for the day at the top so when we use panda's remove duplicates we keep it\n",
    "# This method has an assumption that we highest measurment in the day is the last, but that is not necessarily true because the flag indicates 24 hours not \"day\"\n",
    "# However, the schema does indicate a way to get the time to properly filter for non-overlapping readings\n",
    "station_prcp_long_nodup = station_prcp_long_nodup.sort_values(by=['usaf', 'mo', 'da', 'prcp'], ascending=False)\n",
    "\n",
    "# this view let me confirm what I was getting for the problematic station (999999)\n",
    "# station_prcp_long_nodup2.iloc[9000:9050]\n",
    "\n",
    "station_prcp_long_nodup = station_prcp_long_nodup.drop_duplicates([\"usaf\", \"mo\", \"da\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8db0fe-f56c-4ca7-91a0-e99e52939703",
   "metadata": {},
   "source": [
    "#### Get the total precipitation by station for the year ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c7b6fe-6718-4082-a659-53d6ca59decf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 2522 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>total_precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>999999</td>\n",
       "      <td>809.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>703950</td>\n",
       "      <td>155.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>703610</td>\n",
       "      <td>142.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>703710</td>\n",
       "      <td>102.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>727970</td>\n",
       "      <td>97.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        usaf  total_precipitation\n",
       "2486  999999               809.88\n",
       "138   703950               155.33\n",
       "116   703610               142.47\n",
       "124   703710               102.80\n",
       "2045  727970                97.15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by station and use sum to get total rain for the year and convert series to dataframe\n",
    "station_prcp_total = station_prcp_long_nodup.groupby([\"usaf\"])[\"prcp\"].sum().reset_index()\n",
    "\n",
    "# Change column name\n",
    "station_prcp_total.rename(columns = {'prcp':'total_precipitation'}, inplace = True)\n",
    "\n",
    "# Sort by rain total\n",
    "station_prcp_total = station_prcp_total.sort_values(by=['total_precipitation'], ascending=False)\n",
    "\n",
    "print(f' There are {len(station_prcp_total)} rows')\n",
    "station_prcp_total.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e626c-123f-440d-825f-3c40dd0fb302",
   "metadata": {},
   "source": [
    "#### Get the number of days with precipitation > 6in by station for the year ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35343551-94e9-4ea2-af5b-df0cb42d7f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 27 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>high_prcp_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>999999</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720357</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>720282</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>720384</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>720401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      usaf  high_prcp_days\n",
       "26  999999               8\n",
       "1   720357               2\n",
       "0   720282               2\n",
       "2   720384               2\n",
       "3   720401               1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter stations to only include precipitation over 6in and keep only the station and precipitation columns\n",
    "station_prcp_filter = station_prcp_long_nodup[station_prcp_long_nodup[\"prcp\"] > 6]\n",
    "station_prcp_filter = station_prcp_filter[[\"usaf\", \"prcp\"]]\n",
    "\n",
    "# Group by station and count how many there are\n",
    "station_prcp_count = station_prcp_filter.groupby([\"usaf\"]).count().reset_index()\n",
    "\n",
    "station_prcp_count.head()\n",
    "\n",
    "# Change column name\n",
    "station_prcp_count.rename(columns = {'prcp':'high_prcp_days'}, inplace = True)\n",
    "# Sort descending to gut check top of list\n",
    "station_prcp_count = station_prcp_count.sort_values(by=['high_prcp_days'], ascending=False)\n",
    "\n",
    "print(f' There are {len(station_prcp_count)} rows')\n",
    "station_prcp_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a2fe8-4877-4e61-8329-0f124b60b6f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Query for count of days with 6+ inches of snow in a year ###\n",
    "SchemaField('sndp', 'FLOAT', 'NULLABLE', None, \"Snow depth in inches to tenths--last report for the day if reported more thanonce. Missing = 999.9 Note: Most stations do not report '0' ondays with no snow on the ground--therefore, '999.9' will often appear on these days\", (), None)\n",
    "\n",
    "The snow depth is how much snow is on the ground at the time the station takes a measurement, not the amount of new snow.\n",
    "We chose to approximate snowfall by taking the difference of snow depth day day n - day (n-1) using the maximum snow depth reading per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39f8445d-5960-4549-a861-ac47ac9a7ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 2523 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>high_sndp_change_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>720854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720993</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>722008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaf  high_sndp_change_days\n",
       "0  720854                      0\n",
       "1  720993                      0\n",
       "2  722008                      0\n",
       "3  722061                      0\n",
       "4  722160                      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a query for the sum of snow depth and count of days with 6 or more inches for each station over the year\n",
    "# Some stations have multiple readings within a day but we do not have a timestamp to filter for exact day-to-day\n",
    "# Instead we pull the max reading in a day for the approximation\n",
    "aggregate_query = '''\n",
    "WITH SnowDepthChanges AS (\n",
    "  SELECT DISTINCT\n",
    "    s.usaf,  -- Replace \"stn\" with \"usaf\"\n",
    "    g.date,\n",
    "    MAX(g.sndp) AS max_snow_depth,\n",
    "    CASE WHEN MAX(g.sndp) >= 6.0 THEN 1 ELSE 0 END AS saw_6_or_more_inches\n",
    "  FROM `bigquery-public-data.noaa_gsod.gsod2022` AS g\n",
    "  JOIN `bigquery-public-data.noaa_gsod.stations` AS s ON g.stn = s.usaf\n",
    "  WHERE s.country = \"US\" AND s.state <> \"None\" \n",
    "  GROUP BY s.usaf, g.date  -- Replace \"stn\" with \"usaf\"\n",
    ")\n",
    "\n",
    "SELECT\n",
    "  usaf,  -- Replace \"stn\" with \"usaf\"\n",
    "  SUM(CASE WHEN snow_depth_change >= 6.0 THEN 1 ELSE 0 END) AS high_sndp_change_days\n",
    "FROM (\n",
    "  SELECT\n",
    "    usaf,  -- Replace \"stn\" with \"usaf\"\n",
    "    date,\n",
    "    max_snow_depth,\n",
    "    CASE\n",
    "      WHEN LAG(date, 1) OVER (PARTITION BY usaf ORDER BY date) IS NOT NULL THEN\n",
    "        max_snow_depth - LAG(max_snow_depth, 1, 0) OVER (PARTITION BY usaf ORDER BY date)\n",
    "      ELSE 0  -- Set the snow_depth_change to 0 for the first day of the year\n",
    "    END AS snow_depth_change\n",
    "  FROM SnowDepthChanges\n",
    ") AS Subquery\n",
    "GROUP BY usaf  -- Replace \"stn\" with \"usaf\"\n",
    "ORDER BY high_sndp_change_days\n",
    "'''\n",
    "\n",
    "station_snow_result = client.query(aggregate_query)  # API request\n",
    "station_snow_data = station_snow_result.result()  # Waits for query to finish\n",
    "\n",
    "# Put the query into a dataframe\n",
    "six_inches_snow_df = station_snow_result.to_dataframe()\n",
    "\n",
    "print(f' There are {len(six_inches_snow_df)} rows')\n",
    "six_inches_snow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba334fd5-9a51-46b4-a80e-d69dcb2b37d6",
   "metadata": {},
   "source": [
    "### Query for count of days with tornadoes in a year ###\n",
    "SchemaField('tornado_funnel_cloud', 'STRING', 'NULLABLE', None, 'Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day', (), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506c1057-492d-4071-b3ea-aa92145ea3a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2523 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>days_with_tornado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>722015</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>722010</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>722039</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722103</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>722020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaf  days_with_tornado\n",
       "0  722015                  8\n",
       "1  722010                  4\n",
       "2  722039                  4\n",
       "3  722103                  2\n",
       "4  722020                  2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query to get the number of days with tornadoes for each station (usaf)\n",
    "aggregate_query = (\n",
    "    'SELECT s.usaf, '\n",
    "    # Some stations have more than one reading in a day but that could still refer to a single event \n",
    "    # so we refer to the number of days with tornadoes rather than the number of tornadoes and do a distinct filter\n",
    "    'COUNT(DISTINCT CASE WHEN g.tornado_funnel_cloud = \"1\" THEN DATE(g.date) ELSE NULL END) AS days_with_tornado '\n",
    "    'FROM `bigquery-public-data.noaa_gsod.gsod2022` AS g '\n",
    "    'INNER JOIN `bigquery-public-data.noaa_gsod.stations` AS s ON g.stn = s.usaf '\n",
    "    'WHERE s.country = \"US\" AND s.state <> \"None\" '\n",
    "    'GROUP BY s.usaf '\n",
    "    'ORDER BY days_with_tornado DESC'\n",
    ")\n",
    "\n",
    "# API request\n",
    "station_tornado_result = client.query(aggregate_query)\n",
    "station_tornado_data = station_tornado_result.result()\n",
    "\n",
    "# Put the query into a dataframe\n",
    "station_tornado_df = station_tornado_result.to_dataframe()\n",
    "\n",
    "print(f'There are {len(station_tornado_df)} rows')\n",
    "station_tornado_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb5887-bb15-4aa3-bedc-5c94aa85930c",
   "metadata": {},
   "source": [
    "### Query for count of days with hail in a year ###\n",
    "SchemaField('hail', 'STRING', 'NULLABLE', None, 'Indicators (1 = yes, 0 = no/not reported) for the occurrence during the day', (), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118cc9e0-56ce-4e87-986b-dc9361b16229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2523 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>days_with_hail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>724057</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704140</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>726510</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>726770</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>742060</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaf  days_with_hail\n",
       "0  724057              27\n",
       "1  704140              12\n",
       "2  726510               5\n",
       "3  726770               5\n",
       "4  742060               5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the query to get the number of days with hail for each station (usaf)\n",
    "aggregate_query = (\n",
    "    'SELECT s.usaf, '\n",
    "    # Some stations have more than one reading in a day but that could still refer to a single event \n",
    "    # so we refer to the number of days with hail rather than the number of hail events and do a distinct filter\n",
    "    'COUNT(DISTINCT CASE WHEN g.hail = \"1\" THEN DATE(g.date) ELSE NULL END) AS days_with_hail '\n",
    "    'FROM `bigquery-public-data.noaa_gsod.gsod2022` AS g '\n",
    "    'INNER JOIN `bigquery-public-data.noaa_gsod.stations` AS s ON g.stn = s.usaf '\n",
    "    'WHERE s.country = \"US\" AND s.state <> \"None\" '\n",
    "    'GROUP BY s.usaf '\n",
    "    'ORDER BY days_with_hail DESC'\n",
    ")\n",
    "\n",
    "# API request\n",
    "station_hail_result = client.query(aggregate_query)\n",
    "station_hail_data = station_hail_result.result()\n",
    "\n",
    "# Put the query into a dataframe\n",
    "station_hail_df = station_hail_result.to_dataframe()\n",
    "\n",
    "print(f'There are {len(station_hail_df)} rows')\n",
    "station_hail_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a82740f-e4ce-422f-9762-05beb516ed7c",
   "metadata": {},
   "source": [
    "## Merge all the data frames together ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f5a306d-cf26-4e2d-a40a-24ac9b4e8729",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are 2522 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>high_prcp_days</th>\n",
       "      <th>high_sndp_change_days</th>\n",
       "      <th>days_with_tornado</th>\n",
       "      <th>days_with_hail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>704540</td>\n",
       "      <td>ADAK (NAS)</td>\n",
       "      <td>AK</td>\n",
       "      <td>51.883</td>\n",
       "      <td>-176.650</td>\n",
       "      <td>+0005.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>41.957418</td>\n",
       "      <td>69.1</td>\n",
       "      <td>46.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>997380</td>\n",
       "      <td>ADAK ISLAND</td>\n",
       "      <td>AK</td>\n",
       "      <td>51.870</td>\n",
       "      <td>-176.630</td>\n",
       "      <td>+0007.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>42.015254</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>703926</td>\n",
       "      <td>AKHIOK</td>\n",
       "      <td>AK</td>\n",
       "      <td>56.933</td>\n",
       "      <td>-154.183</td>\n",
       "      <td>+0013.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>37.401887</td>\n",
       "      <td>71.1</td>\n",
       "      <td>9.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>702686</td>\n",
       "      <td>AKIAK</td>\n",
       "      <td>AK</td>\n",
       "      <td>60.903</td>\n",
       "      <td>-161.231</td>\n",
       "      <td>+0009.1</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>34.427976</td>\n",
       "      <td>75.9</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>999999</td>\n",
       "      <td>ALEKNAGIK 1 NNE</td>\n",
       "      <td>AK</td>\n",
       "      <td>59.284</td>\n",
       "      <td>-158.615</td>\n",
       "      <td>+0024.4</td>\n",
       "      <td>-57.1</td>\n",
       "      <td>52.816638</td>\n",
       "      <td>122.4</td>\n",
       "      <td>809.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        usaf                           name state     lat      lon     elev  \\\n",
       "2000  704540  ADAK (NAS)                       AK  51.883 -176.650  +0005.0   \n",
       "682   997380                    ADAK ISLAND    AK  51.870 -176.630  +0007.0   \n",
       "738   703926                         AKHIOK    AK  56.933 -154.183  +0013.0   \n",
       "547   702686                          AKIAK    AK  60.903 -161.231  +0009.1   \n",
       "13    999999  ALEKNAGIK 1 NNE                  AK  59.284 -158.615  +0024.4   \n",
       "\n",
       "      min_temp  mean_temp  max_temp  total_precipitation  high_prcp_days  \\\n",
       "2000      12.9  41.957418      69.1                46.22             0.0   \n",
       "682       18.7  42.015254      64.9                 0.00             0.0   \n",
       "738        8.1  37.401887      71.1                 9.28             0.0   \n",
       "547      -20.0  34.427976      75.9                 1.45             0.0   \n",
       "13       -57.1  52.816638     122.4               809.88             8.0   \n",
       "\n",
       "      high_sndp_change_days  days_with_tornado  days_with_hail  \n",
       "2000                      0                  0               0  \n",
       "682                       0                  0               0  \n",
       "738                       0                  0               0  \n",
       "547                       0                  0               0  \n",
       "13                        0                  0               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use an inner here to create a basis for all possible without adding NaN rows\n",
    "station_temp_merge = pd.merge(stations_data_df, station_temp_df, how =\"inner\", on = \"usaf\")\n",
    "\n",
    "# Use outer here to include everything as the some remaining dataframes do not\n",
    "# include stations that did not register readings but have valid temperature readings\n",
    "st_temp_prcp_merge = pd.merge(station_temp_merge, station_prcp_total, how =\"outer\", on = \"usaf\")\n",
    "\n",
    "st_temp_prcp_merge2 = pd.merge(st_temp_prcp_merge, station_prcp_count, how =\"outer\", on = \"usaf\")\n",
    "\n",
    "st_temp_prcp_snow = pd.merge(st_temp_prcp_merge2, six_inches_snow_df, how =\"outer\", on = \"usaf\")\n",
    "\n",
    "st_temp_prcp_snow_torn = pd.merge(st_temp_prcp_snow, station_tornado_df, how =\"outer\", on = \"usaf\")\n",
    "\n",
    "st_temp_prcp_snow_torn_hail = pd.merge(st_temp_prcp_snow_torn, station_hail_df, how =\"outer\", on = \"usaf\")\n",
    "\n",
    "station_all = st_temp_prcp_snow_torn_hail\n",
    "\n",
    "# Looking at the csv file, some queries brought in an unknown station with data values of 0\n",
    "# Removing unkown station\n",
    "station_all = station_all.dropna(subset=[\"name\"])\n",
    "\n",
    "\n",
    "# Convert the remaining NaN to zero for reporting and future math\n",
    "station_all = station_all.fillna(0)\n",
    "\n",
    "# Sort by states and name for easy dropdown menu population\n",
    "station_all = station_all.sort_values(by=[\"state\", \"name\"], ascending = [True, True])\n",
    "\n",
    "# # and export if desired at this point\n",
    "# station_all.to_json(\"./data/stations_all.json\", orient=\"records\")\n",
    "# station_all.to_csv(\"./data/stations_all.csv\")\n",
    "# station_all.to_json(\"./data/stations_all.js\", orient=\"records\")\n",
    "\n",
    "print(f' There are {len(station_all)} rows')\n",
    "station_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c782a13-01bb-458a-a8cf-5ce9c764dfb7",
   "metadata": {},
   "source": [
    "### Add Severity rating ###\n",
    "We chose to weight tornadoes heavily due to potential damage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66874f4-d707-4234-9a43-dba4a685be15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaf</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>elev</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>mean_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>total_precipitation</th>\n",
       "      <th>high_prcp_days</th>\n",
       "      <th>high_sndp_change_days</th>\n",
       "      <th>days_with_tornado</th>\n",
       "      <th>days_with_hail</th>\n",
       "      <th>severity_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>704540</td>\n",
       "      <td>ADAK (NAS)</td>\n",
       "      <td>AK</td>\n",
       "      <td>51.883</td>\n",
       "      <td>-176.650</td>\n",
       "      <td>+0005.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>41.957418</td>\n",
       "      <td>69.1</td>\n",
       "      <td>46.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>997380</td>\n",
       "      <td>ADAK ISLAND</td>\n",
       "      <td>AK</td>\n",
       "      <td>51.870</td>\n",
       "      <td>-176.630</td>\n",
       "      <td>+0007.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>42.015254</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>703926</td>\n",
       "      <td>AKHIOK</td>\n",
       "      <td>AK</td>\n",
       "      <td>56.933</td>\n",
       "      <td>-154.183</td>\n",
       "      <td>+0013.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>37.401887</td>\n",
       "      <td>71.1</td>\n",
       "      <td>9.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>702686</td>\n",
       "      <td>AKIAK</td>\n",
       "      <td>AK</td>\n",
       "      <td>60.903</td>\n",
       "      <td>-161.231</td>\n",
       "      <td>+0009.1</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>34.427976</td>\n",
       "      <td>75.9</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>999999</td>\n",
       "      <td>ALEKNAGIK 1 NNE</td>\n",
       "      <td>AK</td>\n",
       "      <td>59.284</td>\n",
       "      <td>-158.615</td>\n",
       "      <td>+0024.4</td>\n",
       "      <td>-57.1</td>\n",
       "      <td>52.816638</td>\n",
       "      <td>122.4</td>\n",
       "      <td>809.88</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        usaf                           name state     lat      lon     elev  \\\n",
       "2000  704540  ADAK (NAS)                       AK  51.883 -176.650  +0005.0   \n",
       "682   997380                    ADAK ISLAND    AK  51.870 -176.630  +0007.0   \n",
       "738   703926                         AKHIOK    AK  56.933 -154.183  +0013.0   \n",
       "547   702686                          AKIAK    AK  60.903 -161.231  +0009.1   \n",
       "13    999999  ALEKNAGIK 1 NNE                  AK  59.284 -158.615  +0024.4   \n",
       "\n",
       "      min_temp  mean_temp  max_temp  total_precipitation  high_prcp_days  \\\n",
       "2000      12.9  41.957418      69.1                46.22             0.0   \n",
       "682       18.7  42.015254      64.9                 0.00             0.0   \n",
       "738        8.1  37.401887      71.1                 9.28             0.0   \n",
       "547      -20.0  34.427976      75.9                 1.45             0.0   \n",
       "13       -57.1  52.816638     122.4               809.88             8.0   \n",
       "\n",
       "      high_sndp_change_days  days_with_tornado  days_with_hail  \\\n",
       "2000                      0                  0               0   \n",
       "682                       0                  0               0   \n",
       "738                       0                  0               0   \n",
       "547                       0                  0               0   \n",
       "13                        0                  0               0   \n",
       "\n",
       "      severity_rating  \n",
       "2000              0.0  \n",
       "682               0.0  \n",
       "738               0.0  \n",
       "547               0.0  \n",
       "13                8.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_all[\"severity_rating\"] = station_all[\"days_with_tornado\"]*4 + station_all[\"days_with_hail\"] + station_all[\"high_prcp_days\"] + station_all[\"high_sndp_change_days\"]\n",
    "\n",
    "# and export\n",
    "station_all.to_json(\"../data/stations_all.json\", orient=\"records\")\n",
    "station_all.to_csv(\"../data/stations_all.csv\")\n",
    "station_all.to_json(\"../data/stations_all.js\", orient=\"records\")\n",
    "\n",
    "# Sort by severity for viewing purposes only to verify math\n",
    "# station_all = station_all.sort_values(by=['severity_rating'], ascending=False)\n",
    "\n",
    "station_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846f0c0-ee60-4803-8cfd-848461d90f6d",
   "metadata": {},
   "source": [
    "## Update js export to work with our JavaScript code ##\n",
    "For the use with our javascript, we want \"let stations_all = \" to precede the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a78ceee3-3049-4a1c-b182-12c52f2bac2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../data/stations_all.js\", 'r+') as file:\n",
    "    # read the contents into a variable\n",
    "    content = file.read()\n",
    "    # set cursor to start of file\n",
    "    file.seek(0, 0)\n",
    "    # write the desired starter text and rewrite the original content\n",
    "    file.write(\"let stations_all = \" + content)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb40804b-6f8c-4bc9-8d48-fd9313e888f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
